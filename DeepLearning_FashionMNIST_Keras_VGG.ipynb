{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepLearning_FashionMNIST_Keras_VGG.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPNJoWHGplLfV5d04nj2Za0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielaolage/machineLearning/blob/master/DeepLearning_FashionMNIST_Keras_VGG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GCblGUcC57o"
      },
      "source": [
        "\n",
        "# Classificação Fashion MNIST\n",
        "VGG16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PqiKbO7C6dW"
      },
      "source": [
        "import numpy as np;                       #importa biblioteca para manipulação de matrizes\n",
        "from matplotlib import pyplot as plt;     #importa bilbioteca para criação de gráficos\n",
        "\n",
        "#início das importações de classes do Keras (modelos de Deep Learning)\n",
        "from keras.datasets import fashion_mnist; #importa dataset fashion_mnist\n",
        "from keras.models import Sequential       #importa um modelo sequencial\n",
        "from keras.layers import Dense            #importa camadas totalmente conectadas\n",
        "from keras.layers import Dropout          #importa a estrutura de dropout\n",
        "from keras.utils import np_utils          #importa biblioteca de utilidades do Keras\n",
        "\n",
        "from keras.applications.vgg16 import VGG16;\n",
        "from tensorflow.image import resize "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnH94SmaDhfW"
      },
      "source": [
        "Carregando o dataset em entrada e saida de treino e entrada e saída de teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4qIS0BPDjgG"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-KscqQOD1ZF"
      },
      "source": [
        "print(X_train.shape) # imprime o tamanho do vetor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drf6PaAw4Fkq"
      },
      "source": [
        "## O elemento do índice 4000 do vetor de treinamento corresponde a qual classe? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95eM20fJokr1"
      },
      "source": [
        "first_image = X_train[4000]\n",
        "first_image = np.array(first_image, dtype='float')\n",
        "pixels = first_image.reshape(28,28)\n",
        "plt.imshow(pixels, cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "print(y_train[4000]) # imprime indice 4000 da classe de imagem de treino"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLIzJkWp6Cec"
      },
      "source": [
        "# O elemento do índice 4000 do vetor de treinamento corresponde a qual classe? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_KrBZtYC9JV"
      },
      "source": [
        "first_image = X_test[4000]\n",
        "first_image = np.array(first_image, dtype='float')\n",
        "pixels = first_image.reshape(28,28)\n",
        "plt.imshow(pixels, cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "print(X_test[4000]) # imprime indice 4000 da classe de imagem de treino"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0OvphvIEX6G"
      },
      "source": [
        "# Quantos são os pixels de cada amostra depois de transformadas para serem utilizadas na Vgg-Net?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buRfMqmNpt2c"
      },
      "source": [
        "num_pixels = X_train.shape[1] * X_train.shape[2] # calcula o total de pixels da imagem\n",
        "print(num_pixels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIBAx6K3EZ7v"
      },
      "source": [
        "# transforma pixels para float\n",
        "X_train2 = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')\n",
        "X_test2 = X_test.reshape(X_test.shape[0], num_pixels).astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-RynAw2EsBd"
      },
      "source": [
        "# normaliza os valores entre 0 e 1\n",
        "X_train2 = X_train2 / 255\n",
        "X_test2 = X_test2 / 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUh9YFQNqNZ7"
      },
      "source": [
        "# transforma os y em one-hot vector\n",
        "y_train_h = np_utils.to_categorical(y_train)\n",
        "y_test_h = np_utils.to_categorical(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Cmsb2l-EkED"
      },
      "source": [
        "# Quantas são as classes presentes no problema? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fp4rSVYWEkjB"
      },
      "source": [
        "# obtém o número de classes do problema\n",
        "num_classes = y_test_h.shape[1]\n",
        "print(num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVLS7qBv8VV3"
      },
      "source": [
        "# Caso você tente utilizar a VGG-Net com as imagens originais, qual erro é obtido? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uvrj56E8Ucf"
      },
      "source": [
        "model = VGG16(include_top=False, input_shape=(28, 28, 1))\n",
        "model = VGG16(weights=None, input_shape=(28, 28, 1), classes=10)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7eQdm4S7hvj"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouhZeWlMAdMz"
      },
      "source": [
        "#transforma os pixels para 32 x 32 x 3 canais\n",
        "X_train_1 = np.expand_dims(X_train, axis=-1)  # aumenta uma dimensão no vetor\n",
        "X_train_1 = np.repeat(X_train_1, 3, axis=-1)  # cria 3 canais\n",
        "X_train_resize = resize(X_train_1, [32,32])   # redimensiona\n",
        "\n",
        "print(X_train_resize.shape) # imprime o tamanho do vetor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42III9OWFsbH"
      },
      "source": [
        "# Quantos são os pixels de cada amostra depois de transformadas para serem utilizadas na Vgg-Net? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64iiVCpKFsnP"
      },
      "source": [
        "new_num_pixels = X_train_resize.shape[1] * X_train_resize.shape[2] # calcula o total de pixels da imagem\n",
        "print(new_num_pixels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PEFFoUXG_1_"
      },
      "source": [
        "# Quantos são os parâmetros treináveis da VGG16? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DY9shkaB2b7"
      },
      "source": [
        "model = VGG16(include_top=False, input_shape=(32, 32, 3))\n",
        "model = VGG16(weights=None, input_shape=(32, 32, 3), classes=10)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqF8X9iO_H7D"
      },
      "source": [
        "# compila o modelo criado\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X_train2, y_train_h, validation_data=(X_test2, y_test_h), epochs=20, verbose=1, batch_size = 100) # executa o treinamento\n",
        "\n",
        "scores = model.evaluate(X_test2, y_test_h, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwathiPE_Ijr"
      },
      "source": [
        "x = X_train2[4000]\n",
        "print(x.shape)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "print(x.shape)\n",
        "\n",
        "#imprime a avaliação da amostra\n",
        "print(model.predict(x))\n",
        "print(numpy.argmax(model.predict(x), axis=-1))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}